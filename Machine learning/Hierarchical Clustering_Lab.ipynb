{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name=\"0\">Hierarchical Clustering</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. <a href=\"#1\">Read the dataset</a>\n",
    "2. <a href=\"#2\">Data investigation</a>\n",
    "3. <a href=\"#3\">Data preprocessing </a>\n",
    "4. <a href=\"#4\">Features transformation </a>\n",
    "4. <a href=\"#5\">Training datasets</a>\n",
    "5. <a href=\"#6\">Improvement ideas</a>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. <a name=\"1\">Read the dataset</a>\n",
    "(<a href=\"#0\">Go to top</a>)\n",
    "\n",
    "First dowmload the data set from this link https://www.kaggle.com/fernandol/countries-of-the-world\n",
    "then import it in python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the data\n",
    "\n",
    "data_path = ''  #the path where you downloaded the data\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "print('The shape of the dataset is:', df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. <a name=\"2\">Data investigation</a>\n",
    "(<a href=\"#0\">Go to top</a>)\n",
    "\n",
    "in this part you need to check the data quality and assess any issues in the data as:\n",
    "- null values in each column \n",
    "- each column has the proper data type\n",
    "- outliers\n",
    "- duplicate rows\n",
    "- distribution for each column (skewness)\n",
    "<br>\n",
    "\n",
    "**comment each issue you find** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see the data types and non-null values for each column\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(df.isnull().sum(axis=0)*100/df.shape[0],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will print basic statistics for numerical columns\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. <a name=\"3\">Data preprocessing</a>\n",
    "(<a href=\"#0\">Go to top</a>)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define below all the issues that you had found in the previous part\n",
    "1-           <br>\n",
    "2-           <br>\n",
    "3-           <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a copy for the original dataset\n",
    "df_copy=df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for each issue adapt this methodology \n",
    "- start by defining the solution\n",
    "- apply this solution onn the data\n",
    "- test the solution to make sure that you have solved the issue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First issue**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#solution \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Second issue**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#solution \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. <a name=\"4\">Features transformation</a>\n",
    "(<a href=\"#0\">Go to top</a>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*What is the feature scaling technique that would use and why?* <br>\n",
    "*return to this section again and try another technique and see how that will impact your result*<br>\n",
    "for more details on different methods for scaling check these links\n",
    "- https://scikit-learn.org/stable/modules/preprocessing.html#preprocessing\n",
    "- https://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing\n",
    "- https://www.analyticsvidhya.com/blog/2020/07/types-of-feature-transformation-and-scaling/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. <a name=\"5\">Training and hyperparamter tuning</a>\n",
    "(<a href=\"#0\">Go to top</a>)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start the training process we need to specify 3 paramters:<br>\n",
    "1- Linkage criteria : The linkage criterion determines the distance between two clusters\n",
    "    - Complete-Linkage Clustering\n",
    "    - Single-Linkage Clustering\n",
    "    - Average-Linkage Clustering\n",
    "    - Centroid Linkage Clustering\n",
    "2- Distance function:\n",
    "    - Euclidean Distance \n",
    "    - Manhattan Distance \n",
    "    - Mahalanobis distance \n",
    "3- Number of clusters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Number of clusters*\n",
    "Use Dendograms to specify the optimum number of clusters\n",
    "- Compare how changing linkage criteria or distance function would affect the optimum number of clusters\n",
    "- you can use silhouette_score or any other evalution method to help you determine the optimum number of clusters\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.silhouette_score.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.cluster.hierarchy as shc\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.title(\"Counters Dendograms\")\n",
    "dend = shc.dendrogram(shc.linkage(y=... , method=...,metric=...),orientation='right') #fill y with your dataframe\n",
    "                                                                                      #and method with linkage criteria\n",
    "                                                                                      #and metric with distance function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. <a name=\"6\">improvement ideas</a>\n",
    "(<a href=\"#0\">Go to top</a>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Try to use PCA to reduce the number of features and compare how this will affect the clustring process\n",
    "- Try to run your code again but with different tranformation technique\n",
    "- Implement gap statistics method and use it as evaluation metric and compare the result with what you did before https://www.datanovia.com/en/lessons/determining-the-optimal-number-of-clusters-3-must-know-methods/#gap-statistic-method "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
